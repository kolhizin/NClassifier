{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.sampletools' from 'd:\\\\Programming\\\\NClassifier\\\\dev_tests\\\\tf01_cnn_detect\\\\utils\\\\sampletools.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os, os.path\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import utils.sampletools as smpl\n",
    "\n",
    "importlib.reload(smpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_with_target(observation, path, max_size, min_size, size_step, sample_size, sample_stride):\n",
    "    def expand2tuple(x):\n",
    "        if type(x) in (tuple, list, np.ndarray):\n",
    "            return x\n",
    "        return (x, x)\n",
    "\n",
    "    imgregions = [smpl.transform_dictregion_to_region(x) for x in observation['regions']]\n",
    "\n",
    "    fname = os.path.join(path, observation['imgName'])\n",
    "    img = cv2.imread(fname)\n",
    "    imgsize = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    loc_max_size = expand2tuple(max_size)\n",
    "    loc_min_size = expand2tuple(min_size)\n",
    "    loc_size_step = expand2tuple(size_step)\n",
    "    loc_sample_size = expand2tuple(sample_size)\n",
    "    loc_sample_stride = expand2tuple(sample_stride)\n",
    "\n",
    "    if imgsize[0] > loc_max_size[0] or imgsize[1] > loc_max_size[1]:\n",
    "        size_factor = min(loc_max_size[0] / imgsize[0], loc_max_size[1] / imgsize[1])\n",
    "        #deliberately floor in order not to exceed max_size\n",
    "        imgsize = (int(np.floor(imgsize[0] * size_factor)), int(np.floor(imgsize[1] * size_factor)))\n",
    "\n",
    "    samples = smpl.generate_sample_chain(imgsize, loc_min_size, loc_size_step, loc_sample_size, loc_sample_stride)\n",
    "    targets = smpl.calculate_sample_chain_target(samples, imgregions)\n",
    "    fullsample, size_chain = smpl.transform_sample_chain_to_linear_form(samples, targets)\n",
    "    return fullsample, size_chain, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src_path = '../../dev_datasets/faceimages/'\n",
    "#src_file = 'eye.json'\n",
    "\n",
    "src_path = '../../dev_datasets/pass_sample/'\n",
    "src_file = 'pass_number_vertical.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(src_path, src_file), 'r') as f:\n",
    "    src_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ../../dev_datasets/pass_sample/01_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/02_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/03_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/04_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/05_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/06_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/08_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/08b_pass_number_vertical.pickle\n",
      "Processed ../../dev_datasets/pass_sample/test_vs_pass_number_vertical.pickle\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "desc_name = src_file.split('.')[0]\n",
    "for v in src_sample.values():\n",
    "    sample, size_chain, fname = generate_sample_with_target(v, src_path,\n",
    "                                    max_size=1024, min_size=32, size_step=0.7071,\n",
    "                                    sample_size=16, sample_stride=2)\n",
    "    img_name = os.path.split(fname)[1].split('.')[0]\n",
    "    sname = os.path.join(src_path,  '{0}_{1}.pickle'.format(img_name, desc_name))\n",
    "    with open(sname, 'wb') as f:\n",
    "        pickle.dump((sample, size_chain, fname), f)\n",
    "    print('Processed {}'.format(sname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass_number_vertical.json:\n",
    "#128 - 3s\n",
    "#256 - 9s\n",
    "#512 - 38s\n",
    "#1024 - 150s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
